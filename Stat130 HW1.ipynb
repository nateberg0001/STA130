{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d7ac37",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca82e6",
   "metadata": {},
   "source": [
    "I intialized my conversation with the ChatBot as follows:\n",
    "\"hi i have a dataset located here: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv. How can i use pandas and python to import the data and confirm it has missing values?\"\n",
    "The following code was generated by ChatBot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86469464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "haha\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574fcc7",
   "metadata": {},
   "source": [
    "This is ChatBot's Description of the Code:\n",
    "\"This code will load the dataset into a pandas DataFrame and then use the isnull() method to identify missing values. The sum() function will give you the total count of missing values in each column1.\" \n",
    "\n",
    "This report shows that their are 11 occurences of missing 'song' entries.\n",
    "\n",
    "Link to Full Discussion: https://copilot.microsoft.com/sl/eoqTwJNxy68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898fb30d",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0f3a0",
   "metadata": {},
   "source": [
    "I remember from lecture I can get the shape of a dataframe using the df.shape. However, as the question requests I'll start a conversation as if I didn't know that.\n",
    "This is what I said to the ChatBot:\n",
    "\"I have a csv file at address https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv. I need help understanding the dimensions of the data. In other words, what are the number of rows and columns of the data set?\"\n",
    "\n",
    "The following code was developed by the bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1745c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e32a2",
   "metadata": {},
   "source": [
    "In addition, the Chatbot said:\n",
    "\"Sure, I can help with that! Let’s take a look at the CSV file to determine its dimensions. I’ll load the data and get back to you with the number of rows and columns. Just a moment, please. Alright, the dataset has 391 rows and 16 columns. [...] This code will load the CSV file from the provided URL and print out the number of rows and columns.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef956322",
   "metadata": {},
   "source": [
    "To answer part 2, I asked: \"What are the definitions of \"observations\" and \"variables\" in the scope of my data?\" It then responded with a definition of each term, which I will summarize below:\n",
    "\n",
    "Observations are the entries of data. These are organized into rows and this case represent individual villagers.\n",
    "Varibles are the values associated with the observations. These are organized into columns and this case reflect the characteristics of the villagers. For example, each villager's name, species, or personality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f34648",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A complete summary of my conversation with the Chatbot can be viewed here:\n",
    "https://copilot.microsoft.com/sl/hBSk2c8KbaC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779db5dd",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79af1d",
   "metadata": {},
   "source": [
    "I already know how I could use df.describe() and df['column'].value_counts() methods to get summaries of the data. But I'll start a conservation with the chatBot as if I didn't know for practice.\n",
    "\n",
    "I intialized the conversation with a question: \n",
    "\"I have a csv file with an address of https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv. How can I use pandas and python to summarize the data? More specifically, how can I use the methods df.describe() and df.['column'].value_counts() to achieve this?\"\n",
    "\n",
    "It responded:\n",
    "\"Sure, I can help you with that! Here’s a step-by-step guide on how to summarize your data using pandas in Python.\"\n",
    "\n",
    "In addition it produced the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943905a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "             row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Species Counts:\n",
      " species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "summary_stats = df.describe()\n",
    "print(\"Summary Statistics:\\n\", summary_stats)\n",
    "\n",
    "# Count unique values in the 'species' column\n",
    "species_counts = df['species'].value_counts()\n",
    "print(\"\\nSpecies Counts:\\n\", species_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab360e6",
   "metadata": {},
   "source": [
    "Finally, Chatbot describes the functionality of this code:\n",
    "\"This will give you a comprehensive summary of your data, including both numerical statistics [via df.describe()] and the distribution of values in specific columns [via df.['column'].value_counts()].\" \n",
    "\n",
    "A complete conversation with the ChatBot can be found here:\n",
    "https://copilot.microsoft.com/sl/gHQz11JWjiC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40bb61",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a40fd",
   "metadata": {},
   "source": [
    "I need to figure out how pandas deals with nonnumerical values and empty cells when using the numerical analysis method df.describe(). To help me, I asked the ChatBot the following question:\n",
    "\n",
    "\"I have csv file addressed at  https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv. It has some nonnumerical values and empty cells. When I call the df.describe() method how does the existence of the irregular data affect the pandas method? And more specifically how does the columns intially analyzed compare with the shape of the data and the values of count returned by the method?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babcbb5",
   "metadata": {},
   "source": [
    "It responded with a lot of text, which I will summarize here:\n",
    "Without an arguments, the df.describe() method will only analyse the columns with numerical values. However, if you include the argument columns=all, it will analyze all columns. Empty cells, called NaN's, are also ignored in the analysis and the count value reflects the number of non-empty cells in the column. Because of this the count returned may be less then the total number of rows. \n",
    "\n",
    "It produced the following code to illustrate some of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e11edec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Describe the DataFrame\n",
    "description = df.describe(include='all')\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b736d",
   "metadata": {},
   "source": [
    "It is important to note that some columns like 'age' have a count less the the total column amount of 891 (as shown by the df.shape attribute below). This suggests that there are missing data in the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98fc105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "(891, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Describe the DataFrame\n",
    "description = df.describe()\n",
    "print(description)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf164f93",
   "metadata": {},
   "source": [
    "I changed the code above to get rid of the columns=all arguement to show that now only the numerical columns will be analyzed. \n",
    "\n",
    "A complete conversation for this question with the chatBot can be found here:\n",
    "https://copilot.microsoft.com/sl/gqA8DxqFNuK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040bb23",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab2738",
   "metadata": {},
   "source": [
    "From my understanding, objects have integral information that are stored as \"attributes\". The shape of a data frame in one of the defining properties of a data frame so it is an attribute.\n",
    "On the other hand, the numerical analysis that results from calling the df.describe() function, is not part of data frame nor a defining characteristic of a data frame. Instead, it reads information from the data frame (attributes) and performs an outside action (like a function) to produce statistics. From my understanding, a method is like an individual object's function. For example you cannot perform the .describe() method on a string object.\n",
    "\n",
    "To confirm my understanding, I asked chatBot if I was correct. This was their response:\n",
    "\n",
    "\"Yes, your understanding is correct! Let’s break it down:\n",
    "\n",
    "Attributes: These are integral properties of an object. For a data frame, attributes like its shape (number of rows and columns) are defining characteristics. You can access these directly, for example, using df.shape.\n",
    "\n",
    "Methods: These are functions that belong to an object and can perform actions using the object’s data. The df.describe() method, for instance, reads the data frame’s attributes and performs statistical analysis to produce a summary. This method is specific to data frames and cannot be applied to objects like strings.\n",
    "Your analogy is spot on: methods are like an object’s personal functions. Just as you can’t use df.describe() on a string, you can’t use string-specific methods on a data frame.\"\n",
    "\n",
    "The full conversation with the chatBot for this question can be found here:\n",
    "https://copilot.microsoft.com/sl/gY54CVKTbTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34bc9b",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0327bd0",
   "metadata": {},
   "source": [
    "*This question was done without the assistance of a chatBot\n",
    "\n",
    "\n",
    "Count: How many data entries for a given column (NaNs or empty cells are ignored)\n",
    "\n",
    "\n",
    "Mean: Also known as the average, it gives a estimator of the middle of the data. It is defined as the sum of all entries divided by the number of entries.\n",
    "\n",
    "\n",
    "Std: The Standard Deviation, or an estimate of how variable the data is. An estimator of how far each piece of data is from the mean on average.\n",
    "\n",
    "\n",
    "Min: The minimum value of the entries\n",
    "\n",
    "\n",
    "25%: Also known as the first quartile (Q1), this marks the threshold where 25% of the data is below this mark. It can also be said that 75% of the data is above this mark.\n",
    "\n",
    "\n",
    "50%: The second quartile, more oftenly refered to as the median, is the point in the data where exactly 50% of the data is above and below this value.\n",
    "\n",
    "\n",
    "75%: Also known as the third quartile (Q3), this marks the threshold where 75% of the data is below this mark. It can also be said that 25% of the data is above this mark.\n",
    "\n",
    "\n",
    "Max: The maximum value of the entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8253a1",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a67e2",
   "metadata": {},
   "source": [
    "*This question was done without the assistance of a chatBot\n",
    "\n",
    "\n",
    "The df.dropna() method will get rid of any rows with missing values whereas the del df['column'] operation will get rid of a specified column whether there is missing values or not. While both options can be used to get rid of missing values, I can think of certain scenarios where one might be preferential to another. For example, when the missing data is unpatterned/sporadic, df.dropna() will do a more comphrensive job. In addition, if there is only a couple problematic rows, it will be better for data preservation to use df.dropna() then get rid of whole columns. On the hand if the main problem is just a couple columns who have many missing values, del df['column'] can get rid of the problem while preserving the most data rows. It is also important to note that df.dropna(), with it many optional arguments, is much more customizable.\n",
    "\n",
    "Let's analyze how the titanic file, https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv, can most efficiently purged of its missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbb3c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6665c7",
   "metadata": {},
   "source": [
    "From this analysis, it can be showed that to preserve the maximum data, it would be wisest to delete columns 'age' and 'deck' because they have large amounts of data missing. For 'embark_town', however, only two are missing, so it would be best to just get rid of those two entries instead of the entire column. This can be done by deleting the columns first, then calling df.dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16c9e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only df.dropna(): (182, 15)\n",
      "Only del df['col']: (891, 12)\n",
      "Optimal: (889, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "#Only df.dropna()\n",
    "df = pd.read_csv(url)\n",
    "df=df.dropna()\n",
    "print(\"Only df.dropna(): \" + str(df.shape))\n",
    "#Only del df['col']\n",
    "df = pd.read_csv(url)\n",
    "del df['age']\n",
    "del df['deck']\n",
    "del df['embark_town']\n",
    "print(\"Only del df['col']: \" + str(df.shape))\n",
    "# Optimal\n",
    "df = pd.read_csv(url)\n",
    "del df['age']\n",
    "del df['deck']\n",
    "df=df.dropna()\n",
    "print(\"Optimal: \" + str(df.shape))\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadced04",
   "metadata": {},
   "source": [
    "By the analysis above, df.dropna() resulted in a dataframe with 182x15=2,730 entries, only del df['col'] resulted in 891x12=10,692 entries, but the optimal combination of both yielded 889x13=**11,557** entries! This means the combined approached preserved the most data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d913ff7",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e46e2",
   "metadata": {},
   "source": [
    "I intialized my discussion with the ChatBot with the following:\n",
    "\"What does df.groupby(\"col1\")[\"col2\"].describe() do?\"\n",
    "\n",
    "\n",
    "It responded:\n",
    "\"The expression df.groupby(\"col1\")[\"col2\"].describe() is a method chain in pandas, a popular data manipulation library in Python. Here’s what each part does:\n",
    "\n",
    "df.groupby(\"col1\"): This groups the DataFrame df by the unique values in the column \"col1\". This means that the data is divided into groups based on the unique values found in \"col1\".\n",
    "\n",
    "[\"col2\"]: After grouping, this selects the column \"col2\" from the grouped data. Essentially, it focuses on the \"col2\" data within each group defined by \"col1\".\n",
    "\n",
    ".describe(): This computes summary statistics for \"col2\" within each group. For each unique value in \"col1\", it provides descriptive statistics for \"col2\" \"\n",
    "\n",
    "Now I know what it does, I can show what this line of code would do in the villagers csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6067d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_n        id      name  gender    species birthday personality  \\\n",
      "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
      "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
      "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
      "3        6        al        Al    male    gorilla    10-18        lazy   \n",
      "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
      "..     ...       ...       ...     ...        ...      ...         ...   \n",
      "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
      "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
      "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
      "389    481      zell      Zell    male       deer      6-7        smug   \n",
      "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
      "\n",
      "                song    phrase            full_id  \\\n",
      "0         Steep Hill   aye aye   villager-admiral   \n",
      "1            DJ K.K.  sidekick   villager-agent-s   \n",
      "2         K.K. House   snuffle     villager-agnes   \n",
      "3         Steep Hill   Ayyeeee        villager-al   \n",
      "4        Forest Life  it'sa me   villager-alfonso   \n",
      "..               ...       ...                ...   \n",
      "386         My Place    hay-OK    villager-winnie   \n",
      "387        K.K. Song   snarrrl  villager-wolfgang   \n",
      "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
      "389         K.K. D&B     pronk      villager-zell   \n",
      "390  Spring Blossoms     bloop    villager-zucker   \n",
      "\n",
      "                                                   url  \n",
      "0    https://villagerdb.com/images/villagers/thumb/...  \n",
      "1    https://villagerdb.com/images/villagers/thumb/...  \n",
      "2    https://villagerdb.com/images/villagers/thumb/...  \n",
      "3    https://villagerdb.com/images/villagers/thumb/...  \n",
      "4    https://villagerdb.com/images/villagers/thumb/...  \n",
      "..                                                 ...  \n",
      "386  https://villagerdb.com/images/villagers/thumb/...  \n",
      "387  https://villagerdb.com/images/villagers/thumb/...  \n",
      "388  https://villagerdb.com/images/villagers/thumb/...  \n",
      "389  https://villagerdb.com/images/villagers/thumb/...  \n",
      "390  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "[391 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alligator</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anteater</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bear</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bull</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cub</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deer</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duck</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eagle</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elephant</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frog</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goat</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gorilla</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamster</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hippo</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horse</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kangaroo</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>koala</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monkey</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>octopus</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ostrich</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penguin</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pig</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rabbit</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhino</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheep</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squirrel</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolf</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique     top freq\n",
       "species                            \n",
       "alligator     7      2    male    5\n",
       "anteater      7      2  female    4\n",
       "bear         15      2    male    9\n",
       "bird         13      2    male    9\n",
       "bull          6      1    male    6\n",
       "cat          23      2  female   14\n",
       "chicken       9      2    male    5\n",
       "cow           4      1  female    4\n",
       "cub          16      2    male    8\n",
       "deer         10      2    male    6\n",
       "dog          16      2    male    9\n",
       "duck         17      2  female   10\n",
       "eagle         9      2    male    7\n",
       "elephant     11      2    male    6\n",
       "frog         18      2    male   13\n",
       "goat          8      2    male    4\n",
       "gorilla       9      2    male    7\n",
       "hamster       8      2    male    5\n",
       "hippo         7      2    male    4\n",
       "horse        15      2    male    8\n",
       "kangaroo      8      2  female    6\n",
       "koala         9      2  female    5\n",
       "lion          7      1    male    7\n",
       "monkey        8      2    male    4\n",
       "mouse        15      2  female    8\n",
       "octopus       3      2    male    2\n",
       "ostrich      10      2  female    7\n",
       "penguin      13      2    male    8\n",
       "pig          15      2    male    8\n",
       "rabbit       20      2  female   12\n",
       "rhino         6      2    male    3\n",
       "sheep        13      2  female   10\n",
       "squirrel     18      2  female   13\n",
       "tiger         7      2    male    4\n",
       "wolf         11      2    male    6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df)\n",
    "df.groupby(\"species\")[\"gender\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fbc8e",
   "metadata": {},
   "source": [
    "This code groups the villagers by species (which acts as my 'col1'), then does an analysis of the gender of each species group because I specified the 'gender' column as 'col2'. Because the 'gender' column does not store numerical data, this analysis isn't as robust, showing only 4 statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35f99e",
   "metadata": {},
   "source": [
    "For part two of this question, I asked: \n",
    "\"How does df.describe() and df.groupby(\"col1\")[\"col2\"].describe() handle missing values differently in the count statistic?\"\n",
    "\n",
    "From the chatBots answer, I can say that the difference is that the df.describe() is dataframe wide and its count reflects the non-empty count from the entire dataframe whereas the df.groupby(\"col1\")[\"col2\"].describe() counts the values within each group created by groupby."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9f03b",
   "metadata": {},
   "source": [
    "For the \"NameError: name 'pd' is not defined\" error, I asked chatBot:\n",
    "    \"I got this error: \"NameError: name 'pd' is not defined\"\"\n",
    "In which it successfully recognized the error and gave good suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91422603",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Only df.dropna()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "#Only df.dropna()\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d6fbc",
   "metadata": {},
   "source": [
    "I said: \"I got this error: HTTPError: HTTP Error 404: Not Found ---------------------------------------------------------------------------\n",
    "HTTPError                                 Traceback (most recent call last)\n",
    "Cell In[24], line 4\n",
    "      2 url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "      3 #Only df.dropna()\n",
    "----> 4 df = pd.read_csv(url)\"\n",
    "\n",
    "While I would be able to easily figure out the error myself, chatBot was also able to figure it out and would of helped me if I didn't know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c500dc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mDF\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b5d72",
   "metadata": {},
   "source": [
    "In response, Chatbot said: \n",
    "\"It looks like you encountered a NameError because DF is not defined. In Python, variable names are case-sensitive, so DF and df are considered different variables. In your case, you likely intended to use df, which is the variable where you loaded your data.\" Which would be perfectly effective in helping right the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1255d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1534313123.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[30], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54bb394",
   "metadata": {},
   "source": [
    "It correctly found and corrected the error again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb800edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_n        id      name  gender    species birthday personality  \\\n",
      "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
      "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
      "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
      "3        6        al        Al    male    gorilla    10-18        lazy   \n",
      "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
      "..     ...       ...       ...     ...        ...      ...         ...   \n",
      "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
      "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
      "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
      "389    481      zell      Zell    male       deer      6-7        smug   \n",
      "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
      "\n",
      "                song    phrase            full_id  \\\n",
      "0         Steep Hill   aye aye   villager-admiral   \n",
      "1            DJ K.K.  sidekick   villager-agent-s   \n",
      "2         K.K. House   snuffle     villager-agnes   \n",
      "3         Steep Hill   Ayyeeee        villager-al   \n",
      "4        Forest Life  it'sa me   villager-alfonso   \n",
      "..               ...       ...                ...   \n",
      "386         My Place    hay-OK    villager-winnie   \n",
      "387        K.K. Song   snarrrl  villager-wolfgang   \n",
      "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
      "389         K.K. D&B     pronk      villager-zell   \n",
      "390  Spring Blossoms     bloop    villager-zucker   \n",
      "\n",
      "                                                   url  \n",
      "0    https://villagerdb.com/images/villagers/thumb/...  \n",
      "1    https://villagerdb.com/images/villagers/thumb/...  \n",
      "2    https://villagerdb.com/images/villagers/thumb/...  \n",
      "3    https://villagerdb.com/images/villagers/thumb/...  \n",
      "4    https://villagerdb.com/images/villagers/thumb/...  \n",
      "..                                                 ...  \n",
      "386  https://villagerdb.com/images/villagers/thumb/...  \n",
      "387  https://villagerdb.com/images/villagers/thumb/...  \n",
      "388  https://villagerdb.com/images/villagers/thumb/...  \n",
      "389  https://villagerdb.com/images/villagers/thumb/...  \n",
      "390  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "[391 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52/3079111818.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"species\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df)\n",
    "df.group_by(\"species\")[\"gender\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7090d",
   "metadata": {},
   "source": [
    "After copying the error code, it once again correctly identified and rectified the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "497979a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_n        id      name  gender    species birthday personality  \\\n",
      "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
      "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
      "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
      "3        6        al        Al    male    gorilla    10-18        lazy   \n",
      "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
      "..     ...       ...       ...     ...        ...      ...         ...   \n",
      "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
      "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
      "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
      "389    481      zell      Zell    male       deer      6-7        smug   \n",
      "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
      "\n",
      "                song    phrase            full_id  \\\n",
      "0         Steep Hill   aye aye   villager-admiral   \n",
      "1            DJ K.K.  sidekick   villager-agent-s   \n",
      "2         K.K. House   snuffle     villager-agnes   \n",
      "3         Steep Hill   Ayyeeee        villager-al   \n",
      "4        Forest Life  it'sa me   villager-alfonso   \n",
      "..               ...       ...                ...   \n",
      "386         My Place    hay-OK    villager-winnie   \n",
      "387        K.K. Song   snarrrl  villager-wolfgang   \n",
      "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
      "389         K.K. D&B     pronk      villager-zell   \n",
      "390  Spring Blossoms     bloop    villager-zucker   \n",
      "\n",
      "                                                   url  \n",
      "0    https://villagerdb.com/images/villagers/thumb/...  \n",
      "1    https://villagerdb.com/images/villagers/thumb/...  \n",
      "2    https://villagerdb.com/images/villagers/thumb/...  \n",
      "3    https://villagerdb.com/images/villagers/thumb/...  \n",
      "4    https://villagerdb.com/images/villagers/thumb/...  \n",
      "..                                                 ...  \n",
      "386  https://villagerdb.com/images/villagers/thumb/...  \n",
      "387  https://villagerdb.com/images/villagers/thumb/...  \n",
      "388  https://villagerdb.com/images/villagers/thumb/...  \n",
      "389  https://villagerdb.com/images/villagers/thumb/...  \n",
      "390  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "[391 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: element'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecies\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: element'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df)\n",
    "df.groupby(\"species\")[\"element\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354c04c",
   "metadata": {},
   "source": [
    "ChatBot says: \"The KeyError you're encountering indicates that the column \"element\" does not exist in your DataFrame df. This can happen if the column name is incorrect or if it does not exist in the data you loaded.\" Which is great to help me identify and correct the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13d214c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row_n        id      name  gender    species birthday personality  \\\n",
      "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
      "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
      "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
      "3        6        al        Al    male    gorilla    10-18        lazy   \n",
      "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
      "..     ...       ...       ...     ...        ...      ...         ...   \n",
      "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
      "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
      "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
      "389    481      zell      Zell    male       deer      6-7        smug   \n",
      "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
      "\n",
      "                song    phrase            full_id  \\\n",
      "0         Steep Hill   aye aye   villager-admiral   \n",
      "1            DJ K.K.  sidekick   villager-agent-s   \n",
      "2         K.K. House   snuffle     villager-agnes   \n",
      "3         Steep Hill   Ayyeeee        villager-al   \n",
      "4        Forest Life  it'sa me   villager-alfonso   \n",
      "..               ...       ...                ...   \n",
      "386         My Place    hay-OK    villager-winnie   \n",
      "387        K.K. Song   snarrrl  villager-wolfgang   \n",
      "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
      "389         K.K. D&B     pronk      villager-zell   \n",
      "390  Spring Blossoms     bloop    villager-zucker   \n",
      "\n",
      "                                                   url  \n",
      "0    https://villagerdb.com/images/villagers/thumb/...  \n",
      "1    https://villagerdb.com/images/villagers/thumb/...  \n",
      "2    https://villagerdb.com/images/villagers/thumb/...  \n",
      "3    https://villagerdb.com/images/villagers/thumb/...  \n",
      "4    https://villagerdb.com/images/villagers/thumb/...  \n",
      "..                                                 ...  \n",
      "386  https://villagerdb.com/images/villagers/thumb/...  \n",
      "387  https://villagerdb.com/images/villagers/thumb/...  \n",
      "388  https://villagerdb.com/images/villagers/thumb/...  \n",
      "389  https://villagerdb.com/images/villagers/thumb/...  \n",
      "390  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "[391 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'species' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m----> 7\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43mspecies\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'species' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df)\n",
    "df.groupby(species)[\"gender\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61c2fc",
   "metadata": {},
   "source": [
    "Once again it recognized and suggested changes for the error: \"The NameError you're encountering occurs because species is being treated as a variable rather than a string representing the column name. In pandas operations, column names should be provided as strings.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4355d78",
   "metadata": {},
   "source": [
    "The complete conversation can be accessed here: https://docs.google.com/document/d/1B1GOTzHENSIPr3XpLx4EfBow23oX7MGTsHBkL63jMq4/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1cc7d",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cf3dd",
   "metadata": {},
   "source": [
    "I have not looked at the wiki-textbook or chated a chatbot (unless told do by the assignment) to answer any of my questions about course content, but I am sure if something comes up I can easily access these resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757db658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
